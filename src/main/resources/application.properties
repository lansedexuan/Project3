#web服务端口号server.port=8080##集成百炼-deepseek#langchain4j.open-ai.chat-model.base-url=https://dashscope.aliyuncs.com/compatible#mode/v1#langchain4j.open-ai.chat-model.api-key=${DASH_SCOPE_API_KEY}#langchain4j.open-ai.chat-model.model-name=deepseek-v3##温度系数：取值范围通常在 0 到 1 之间。值越高，模型的输出越随机、富有创造性；## 值越低，输出越确定、保守。这里设置为 0.9，意味着模型会有一定的随机性，生成的回复可能会比较多样化。#langchain4j.open-ai.chat-model.temperature=0.9#langchain4j测试模型langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1langchain4j.open-ai.chat-model.api-key=demolangchain4j.open-ai.chat-model.model-name=gpt-4o-mini#请求和响应日志langchain4j.open-ai.chat-model.log-requests=truelangchain4j.open-ai.chat-model.log-responses=true#ollamalangchain4j.ollama.chat-model.base-url=http://localhost:11434langchain4j.ollama.chat-model.model-name=deepseek-r1:1.5blangchain4j.ollama.chat-model.temperature=0.8langchain4j.ollama.chat-model.timeout=PT60S#请求和响应日志langchain4j.ollama.chat-model.log-requests=truelangchain4j.ollama.chat-model.log-responses=true#阿里百炼平台langchain4j.community.dashscope.chat-model.api-key=${DASH_SCOPE_API_KEY}langchain4j.community.dashscope.chat-model.model-name=qwen-max#集成阿里通义千问-流式输出langchain4j.community.dashscope.streaming-chat-model.api-key=${DASH_SCOPE_API_KEY}langchain4j.community.dashscope.streaming-chat-model.model-name=qwen-plus#集成阿里通义千问-通用文本向量-v3langchain4j.community.dashscope.embedding-model.api-key=${DASH_SCOPE_API_KEY}langchain4j.community.dashscope.embedding-model.model-name=text-embedding-v3#MongoDB连接配置spring.data.mongodb.uri=mongodb://localhost:27017/chat_memory_db#启用日志debug级别logging.level.root=info# 基本数据源配置spring.datasource.url=jdbc:mysql://localhost:3306/guiguxiaozhi?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&useSSL=falsespring.datasource.username=rootspring.datasource.password=010704spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver# 开启 SQL 日志打印mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl