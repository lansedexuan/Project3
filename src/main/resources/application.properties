#web服务端口号server.port=8080##集成百炼-deepseek#langchain4j.open-ai.chat-model.base-url=https://dashscope.aliyuncs.com/compatible#mode/v1#langchain4j.open-ai.chat-model.api-key=${DASH_SCOPE_API_KEY}#langchain4j.open-ai.chat-model.model-name=deepseek-v3##温度系数：取值范围通常在 0 到 1 之间。值越高，模型的输出越随机、富有创造性；## 值越低，输出越确定、保守。这里设置为 0.9，意味着模型会有一定的随机性，生成的回复可能会比较多样化。#langchain4j.open-ai.chat-model.temperature=0.9#langchain4j测试模型langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1langchain4j.open-ai.chat-model.api-key=demolangchain4j.open-ai.chat-model.model-name=gpt-4o-mini#请求和响应日志langchain4j.open-ai.chat-model.log-requests=truelangchain4j.open-ai.chat-model.log-responses=true#ollamalangchain4j.ollama.chat-model.base-url=http://localhost:11434langchain4j.ollama.chat-model.model-name=deepseek-r1:1.5blangchain4j.ollama.chat-model.temperature=0.8langchain4j.ollama.chat-model.timeout=PT60S#请求和响应日志langchain4j.ollama.chat-model.log-requests=truelangchain4j.ollama.chat-model.log-responses=true#阿里百炼平台langchain4j.community.dashscope.chat-model.api-key=${DASH_SCOPE_API_KEY}langchain4j.community.dashscope.chat-model.model-name=qwen-max#MongoDB连接配置spring.data.mongodb.uri=mongodb://localhost:27017/chat_memory_db#启用日志debug级别logging.level.root=info